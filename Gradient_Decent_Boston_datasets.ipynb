{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afda9545",
   "metadata": {},
   "source": [
    "Gradient Descent - Boston Dataset\n",
    "\n",
    "* Boston dataset is one of the datasets available in\n",
    "sklearn.\n",
    "* You are given a Training dataset csv file with X train and\n",
    "Y train data. As studied in lecture, your task is to come up\n",
    "with Gradient Descent algorithm and thus predictions for\n",
    "the test dataset given.\n",
    "\n",
    "Your task is to:\n",
    "1. Code Gradient Descent for N features and come\n",
    "with predictions.\n",
    "2. Try and test with various combinations of learning\n",
    "rates and number of iterations.\n",
    "3. Try using Feature Scaling, and see if it helps you\n",
    "in getting better results.\n",
    "\n",
    "Read Instructions carefully -\n",
    "1. Use Gradient Descent as a training algorithm and\n",
    "submit results predicted.\n",
    "2. Files are in csv format, you can use genfromtxt\n",
    "function in numpy to load data from csv file.\n",
    "Similarly you can use savetxt function to save data\n",
    "into a file.\n",
    "3. Submit a csv file with only predictions for X test\n",
    "data. File name should not have spaces. File should\n",
    "not have any headers and should only have one\n",
    "column i.e. predictions. Also predictions shouldn't be\n",
    "in exponential form.\n",
    "4. Your score is based on coefficient of\n",
    "determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ebda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt, savetxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8199977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = genfromtxt(\"./boston/0000000000002417_training_boston_x_y_train.csv\", delimiter=',', skip_header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e2d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(379,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,0:-1]\n",
    "Y = data[:, -1]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00c2cd",
   "metadata": {},
   "source": [
    "# Building my own gradient decent algorithm for multiplie variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7a6f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X, Y, learning_rate, m):\n",
    "    m_slope=np.zeros(len(X[0])) # final slope\n",
    "    for i in range(len(X)):\n",
    "        x = X[i] # no of columns based on ith row \n",
    "        y = Y[i]\n",
    "        for j in range(len(x)): # for each of jth column in ith row is needed to calculate for cost\n",
    "            # m * x is numpy array it will do the dot product n then sum is applied\n",
    "            # it a derivative w.r.t m\n",
    "            m_slope[j]+=(-2/len(X))*(y-sum(m*x))*x[j]  # dervative of slope\n",
    "    new_m=m-(learning_rate*m_slope) # final slope updatation \n",
    "    return new_m\n",
    "\n",
    "def cost(m, X, Y):\n",
    "    cost=0\n",
    "    for i in range(len(X)):\n",
    "        cost+=(1/len(X))*((Y[i]-sum(m*X[i]))**2)\n",
    "    print(cost)\n",
    "\n",
    "def gradient_decent(X, Y, learning_rate, num_iterations):\n",
    "    m = np.zeros(len(X[0]))\n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(X, Y, learning_rate, m)\n",
    "        print(\"itr= \", i, \"cost=\", end=' ')\n",
    "        cost(m, X, Y)\n",
    "    return m\n",
    "\n",
    "def run(X, Y):\n",
    "    learning_rate = 0.11\n",
    "    num_iterations = 100\n",
    "    # Adding C as 1 to the feature itself, for Mltivariate reg\n",
    "    X = np.append(X, np.ones(len(X)).reshape(-1, 1), axis=1)\n",
    "    m = gradient_decent(X, Y, learning_rate, num_iterations)\n",
    "    return m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40b66786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr=  0 cost= 364.2207823129001\n",
      "itr=  1 cost= 227.07295926827348\n",
      "itr=  2 cost= 145.27146506086993\n",
      "itr=  3 cost= 96.01248803958627\n",
      "itr=  4 cost= 66.18412884892768\n",
      "itr=  5 cost= 48.044725362943794\n",
      "itr=  6 cost= 36.967804164141754\n",
      "itr=  7 cost= 30.170650379759213\n",
      "itr=  8 cost= 25.97298746848971\n",
      "itr=  9 cost= 23.357608261016633\n",
      "itr=  10 cost= 21.707589352143543\n",
      "itr=  11 cost= 20.648244265075636\n",
      "itr=  12 cost= 19.951727070680185\n",
      "itr=  13 cost= 19.479312567906874\n",
      "itr=  14 cost= 19.146414929296892\n",
      "itr=  15 cost= 18.901362467477387\n",
      "itr=  16 cost= 18.712508245097066\n",
      "itr=  17 cost= 18.560397817514882\n",
      "itr=  18 cost= 18.43300751430429\n",
      "itr=  19 cost= 18.32284816796667\n",
      "itr=  20 cost= 18.225202667245515\n",
      "itr=  21 cost= 18.13705289895754\n",
      "itr=  22 cost= 18.056425982089326\n",
      "itr=  23 cost= 17.98199559545105\n",
      "itr=  24 cost= 17.912838552068898\n",
      "itr=  25 cost= 17.848285891355772\n",
      "itr=  26 cost= 17.78783154466078\n",
      "itr=  27 cost= 17.73107609422234\n",
      "itr=  28 cost= 17.677691943489712\n",
      "itr=  29 cost= 17.62740156894531\n",
      "itr=  30 cost= 17.579963780037094\n",
      "itr=  31 cost= 17.535164895556672\n",
      "itr=  32 cost= 17.49281295102433\n",
      "itr=  33 cost= 17.452733786036003\n",
      "itr=  34 cost= 17.41476830780192\n",
      "itr=  35 cost= 17.378770499639355\n",
      "itr=  36 cost= 17.344605909343137\n",
      "itr=  37 cost= 17.312150453755287\n",
      "itr=  38 cost= 17.281289437803835\n",
      "itr=  39 cost= 17.251916724196207\n",
      "itr=  40 cost= 17.2239340132149\n",
      "itr=  41 cost= 17.19725020638537\n",
      "itr=  42 cost= 17.17178083664844\n",
      "itr=  43 cost= 17.147447553194173\n",
      "itr=  44 cost= 17.124177652589506\n",
      "itr=  45 cost= 17.101903650052964\n",
      "itr=  46 cost= 17.08056288617158\n",
      "itr=  47 cost= 17.06009716531733\n",
      "itr=  48 cost= 17.040452422680797\n",
      "itr=  49 cost= 17.021578417308422\n",
      "itr=  50 cost= 17.00342844887887\n",
      "itr=  51 cost= 16.98595909621931\n",
      "itr=  52 cost= 16.96912997577741\n",
      "itr=  53 cost= 16.952903518440397\n",
      "itr=  54 cost= 16.937244763242415\n",
      "itr=  55 cost= 16.922121166630507\n",
      "itr=  56 cost= 16.90750242607447\n",
      "itr=  57 cost= 16.893360316907163\n",
      "itr=  58 cost= 16.8796685413732\n",
      "itr=  59 cost= 16.866402588947786\n",
      "itr=  60 cost= 16.853539607061748\n",
      "itr=  61 cost= 16.84105828143806\n",
      "itr=  62 cost= 16.828938725307985\n",
      "itr=  63 cost= 16.817162376832446\n",
      "itr=  64 cost= 16.805711904106804\n",
      "itr=  65 cost= 16.79457111717602\n",
      "itr=  66 cost= 16.78372488653133\n",
      "itr=  67 cost= 16.77315906760064\n",
      "itr=  68 cost= 16.762860430782418\n",
      "itr=  69 cost= 16.752816596607637\n",
      "itr=  70 cost= 16.74301597564578\n",
      "itr=  71 cost= 16.733447712800743\n",
      "itr=  72 cost= 16.724101635669495\n",
      "itr=  73 cost= 16.71496820666058\n",
      "itr=  74 cost= 16.70603847859354\n",
      "itr=  75 cost= 16.697304053520988\n",
      "itr=  76 cost= 16.688757044534142\n",
      "itr=  77 cost= 16.680390040331865\n",
      "itr=  78 cost= 16.6721960723486\n",
      "itr=  79 cost= 16.66416858425288\n",
      "itr=  80 cost= 16.656301403641585\n",
      "itr=  81 cost= 16.648588715768817\n",
      "itr=  82 cost= 16.641025039159732\n",
      "itr=  83 cost= 16.633605202971424\n",
      "itr=  84 cost= 16.62632432597274\n",
      "itr=  85 cost= 16.619177797024847\n",
      "itr=  86 cost= 16.612161256952763\n",
      "itr=  87 cost= 16.605270581706694\n",
      "itr=  88 cost= 16.598501866718948\n",
      "itr=  89 cost= 16.591851412369937\n",
      "itr=  90 cost= 16.585315710482153\n",
      "itr=  91 cost= 16.57889143176801\n",
      "itr=  92 cost= 16.572575414162266\n",
      "itr=  93 cost= 16.566364651975043\n",
      "itr=  94 cost= 16.560256285806165\n",
      "itr=  95 cost= 16.55424759316586\n",
      "itr=  96 cost= 16.5483359797511\n",
      "itr=  97 cost= 16.542518971330015\n",
      "itr=  98 cost= 16.536794206190947\n",
      "itr=  99 cost= 16.531159428115732\n"
     ]
    }
   ],
   "source": [
    "X= data[:,0:-1]\n",
    "Y = data[:, -1]\n",
    "#adding squared values of each column\n",
    "sq=[]\n",
    "for i in X:\n",
    "    sq.append(i**2)\n",
    "sq=np.array(sq)\n",
    "X=np.append(X, sq, axis=1)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "m=run(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "092c4c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.870445989719263\n",
      "28.59863740125128\n",
      "22.78456922946407\n",
      "24.154785055703755\n",
      "19.347224798555477\n",
      "13.03437545593491\n",
      "27.34351664522876\n",
      "22.969317949015945\n",
      "18.870849780800697\n",
      "23.22612077857668\n",
      "24.8667515427157\n",
      "17.02992130395709\n",
      "18.55421529667459\n",
      "18.795388874605177\n",
      "49.54392099233067\n",
      "23.284910490199486\n",
      "24.393689370611607\n",
      "26.187625507708542\n",
      "18.701333816151248\n",
      "31.51425660264661\n",
      "21.40492168887355\n",
      "24.154468796983384\n",
      "35.40683803113731\n",
      "35.7338714853582\n",
      "32.97159693174076\n",
      "17.06349334955803\n",
      "22.372235702313002\n",
      "31.669268697899007\n",
      "23.067132237578065\n",
      "31.991951025174217\n",
      "16.076821977589503\n",
      "25.737491856444553\n",
      "23.101133751154986\n",
      "23.915855236103706\n",
      "13.23316161579606\n",
      "28.001353744156088\n",
      "24.92273523585821\n",
      "19.19841259778402\n",
      "22.901599306629585\n",
      "9.99572815195414\n",
      "16.985718696801673\n",
      "26.319145090326597\n",
      "29.824017734955454\n",
      "19.363607829989125\n",
      "18.220866665764163\n",
      "13.257646001925401\n",
      "46.994345547104714\n",
      "23.990054907608688\n",
      "31.55990434193138\n",
      "14.29771323410174\n",
      "16.05567703250442\n",
      "41.48734120355262\n",
      "15.032953528271527\n",
      "20.039795660327616\n",
      "14.973273520963097\n",
      "21.48555819959878\n",
      "16.502132220261384\n",
      "22.39116750190151\n",
      "14.427144187115053\n",
      "14.9392353582314\n",
      "11.300243211612221\n",
      "29.39977835402105\n",
      "22.965503485293766\n",
      "25.637734039486354\n",
      "16.22542805174463\n",
      "15.657907570508165\n",
      "34.502403395011754\n",
      "15.372848662133514\n",
      "25.169696089215904\n",
      "21.38435132558449\n",
      "28.658652122057617\n",
      "26.10135373306153\n",
      "15.205310118466942\n",
      "11.810917362643384\n",
      "36.4898650621825\n",
      "23.457047738069857\n",
      "27.272370473147507\n",
      "26.668432148312352\n",
      "14.535563222403201\n",
      "32.141023609043245\n",
      "16.987304891856798\n",
      "21.58733663226702\n",
      "21.973503105651528\n",
      "12.771447251469759\n",
      "15.375412643326715\n",
      "32.04988179551465\n",
      "23.86617397871762\n",
      "12.581272010473281\n",
      "21.051155809313414\n",
      "18.05201875472753\n",
      "21.311477980485385\n",
      "18.49944986490028\n",
      "18.356589585246642\n",
      "12.292191708798725\n",
      "20.617393375910186\n",
      "23.626123821824507\n",
      "42.40966784015104\n",
      "19.045895431376458\n",
      "33.94075695102552\n",
      "25.362411976339274\n",
      "29.358785614835263\n",
      "20.411442151897546\n",
      "23.25293984054693\n",
      "31.51722491626058\n",
      "14.350040940932475\n",
      "25.119682922904826\n",
      "20.824299929215115\n",
      "38.23645311255634\n",
      "23.287731988372\n",
      "14.547900067390163\n",
      "25.737722758108816\n",
      "17.376166876695912\n",
      "13.877198644477584\n",
      "19.211435685512086\n",
      "39.224456619224796\n",
      "20.254750787023973\n",
      "19.89551301193359\n",
      "23.801332520505674\n",
      "21.75294264660435\n",
      "17.353841615617267\n",
      "13.388550165396628\n",
      "35.32577046336142\n",
      "21.703909218617934\n",
      "23.082393163469778\n",
      "21.876567041304508\n",
      "19.680284222306412\n",
      "13.280607799006402\n"
     ]
    }
   ],
   "source": [
    "test_data = genfromtxt(\"./boston/0000000000002417_test_boston_x_test.csv\", delimiter=',', skip_header=0)\n",
    "test_data.shape\n",
    "\n",
    "sq=[]\n",
    "for i in test_data:\n",
    "    sq.append(i**2)\n",
    "sq=np.array(sq)\n",
    "test_data=np.append(test_data, sq, axis=1)\n",
    "\n",
    "testing1=scaler.transform(test_data)\n",
    "x_test=np.append(testing1, np.ones(len(testing1)).reshape(-1, 1), axis=1)\n",
    "ans=[]\n",
    "for i in x_test:\n",
    "    ans.append(sum(i*m)) # captured best values of m from the training data and use it here for testing\n",
    "for i in ans:\n",
    "    print(i)\n",
    "ans=np.array(ans)\n",
    "np.savetxt(X=ans,fname='./boston/Prediction.csv',delimiter=',', fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fead1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e031dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b6955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87656449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1c9144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19c8679f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 13)\n",
      "(114, 13)\n",
      "(265,)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa66646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_Val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2ae48a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9849588503525196 0.8388220523369654\n"
     ]
    }
   ],
   "source": [
    "train_score = model.score(X_train, Y_train)\n",
    "val_score_score = model.score(X_val, Y_val)\n",
    "print(train_score, val_score_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbbb6a",
   "metadata": {},
   "source": [
    "# Scaling and then doing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c1b94e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9849588503525196 0.8390490388444315\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_Val_pred = model.predict(X_val)\n",
    "train_score = model.score(X_train, Y_train)\n",
    "val_score_score = model.score(X_val, Y_val)\n",
    "print(train_score, val_score_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c875ed",
   "metadata": {},
   "source": [
    "* Conclusion : Scaling not changed any output score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a49e531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 13)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = genfromtxt(\"./boston/0000000000002417_test_boston_x_test.csv\", delimiter=',', skip_header=0)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d2778a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8615365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt(\"boston_prediction.csv\", test_predicted, fmt='%1.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb819b",
   "metadata": {},
   "source": [
    "# Adding extra feature and testing the same in datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8dc70414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 52)\n",
      "(114, 52)\n",
      "(265,)\n",
      "(114,)\n",
      "0.985269044068177 0.8471330220304578\n"
     ]
    }
   ],
   "source": [
    "sq=[]\n",
    "for i in X:\n",
    "    sq.append(i**2)\n",
    "sq=np.array(sq)\n",
    "X=np.append(X, sq, axis=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3, random_state=43)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_Val_pred = model.predict(X_val)\n",
    "\n",
    "train_score = model.score(X_train, Y_train)\n",
    "val_score_score = model.score(X_val, Y_val)\n",
    "print(train_score, val_score_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3eecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
